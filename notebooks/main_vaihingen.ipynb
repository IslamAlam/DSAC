{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append source to system files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#Second append the folder path\\n\n",
    "sys.path.insert(0, './../inc')\n",
    "sys.path.insert(0, './../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start script of DSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Dir:/home/jovyan/work/DSAC/notebooks\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from active_contours_fast import draw_poly,derivatives_poly,draw_poly_fill\n",
    "from snake_utils import imrotate, plot_snakes, CNN_B, snake_graph, plot_for_figure\n",
    "from scipy import interpolate\n",
    "from skimage.filters import gaussian\n",
    "import scipy\n",
    "import time\n",
    "import math\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path().resolve()\n",
    "\n",
    "print('Notebook Dir:' + str(BASE_DIR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF issue:\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/issues/24828"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-i\", \"--datapath\", dest=\"inputdatapath\",\n",
    "                    help=\"Enter the path of the dataset report to FILE\", metavar=\"FILE\")\n",
    "parser.add_argument(\"-o\", \"--outputfile\", dest=\"outputfilename\",\n",
    "                    help=\"write report to FILE\", metavar=\"FILE\")\n",
    "\n",
    "parser.add_argument(\"-q\", \"--quiet\",\n",
    "                    action=\"store_false\", dest=\"verbose\", default=True,\n",
    "                    help=\"don't print status messages to stdout\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "print(args.inputdatapath)\n",
    "data_path = str(BASE_DIR.joinpath(str(args.inputdatapath)))  + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snake_process (mapE, mapA, mapB, mapK, init_snake):\n",
    "\n",
    "    for i in range(mapE.shape[3]):\n",
    "        Du = np.gradient(mapE[:,:,0,i], axis=0)\n",
    "        Dv = np.gradient(mapE[:,:,0,i], axis=1)\n",
    "        u = init_snake[:,0:1]\n",
    "        v = init_snake[:,1:2]\n",
    "        du = np.zeros(u.shape)\n",
    "        dv = np.zeros(v.shape)\n",
    "        snake_hist = []\n",
    "        snake_hist.append(np.array([u[:, 0], v[:, 0]]).T)\n",
    "        tic = time.time()\n",
    "        for j in range(1):\n",
    "            u, v, du, dv = sess2.run([tf_u, tf_v, tf_du, tf_dv], feed_dict={tf_Du: Du, tf_Dv: Dv,\n",
    "                                                                               tf_u0: u, tf_v0: v, tf_du0: du, tf_dv0: dv,\n",
    "                                                                               tf_alpha: mapA[:,:,0,i], tf_beta: mapB[:,:,0,i],\n",
    "                                                                               tf_kappa: mapK[:,:,0,i]}) #,options=run_options, run_metadata=run_metadata\n",
    "            snake_hist.append(np.array([u[:, 0], v[:, 0]]).T)\n",
    "\n",
    "        #print('%.2f' % (time.time() - tic) + ' s snake')\n",
    "\n",
    "    return np.array([u[:,0],v[:,0]]).T,snake_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputfile = inputfile[:-4] + \"_features\" + inputfile[-4:]\n",
    "#outputfile = str(args.outputfilename)\n",
    "\n",
    "data_path = str(BASE_DIR.joinpath(str('./../dataset/buildings/')))  + \"/\"\n",
    "model_path = str(BASE_DIR.joinpath(str('./../models/vaihingen/')))  + \"/\"\n",
    "\n",
    "do_plot = True\n",
    "do_train = True\n",
    "start_test = 100\n",
    "\n",
    "\n",
    "#Load data\n",
    "L = 60\n",
    "batch_size = 1\n",
    "numfilt = [32,64,128,128,256,256]\n",
    "im_size = 512\n",
    "out_size = 256\n",
    "\n",
    "csvfile=open(data_path + 'polygons.csv', newline='')\n",
    "reader = csv.reader(csvfile)\n",
    "images = np.zeros([im_size,im_size,3,168])\n",
    "masks = np.zeros([out_size,out_size,1,168])\n",
    "GT = np.zeros([L,2,168])\n",
    "for i in range(168):\n",
    "    corners = reader.__next__()\n",
    "    num_points = np.int32(corners[0])\n",
    "    poly = np.zeros([num_points, 2])\n",
    "    for c in range(num_points):\n",
    "        poly[c, 0] = np.float(corners[1+2*c])*out_size/im_size\n",
    "        poly[c, 1] = np.float(corners[2+2*c])*out_size/im_size\n",
    "    [tck, u] = interpolate.splprep([poly[:, 0], poly[:, 1]], s=2, k=1, per=1)\n",
    "    [GT[:,0,i], GT[:,1,i]] = interpolate.splev(np.linspace(0, 1, L), tck)\n",
    "    this_im  = scipy.misc.imread(data_path+'building_'+str(i+1).zfill(3)+'.tif')\n",
    "    images[:,:,:,i] = np.float32(this_im)/255\n",
    "    img_mask = scipy.misc.imread(data_path+'building_mask_' + str(i+1).zfill(3) + '.tif')/255\n",
    "    masks[:,:,0,i] = scipy.misc.imresize(img_mask,[out_size,out_size])/255\n",
    "GT = np.minimum(GT,out_size-1)\n",
    "GT = np.maximum(GT,0)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    tvars, grads, predE, predA, predB, predK, l2loss, grad_predE, \\\n",
    "    grad_predA, grad_predB, grad_predK, grad_l2loss, x, y_ = CNN_B(im_size, out_size, L, batch_size=1,wd=0.01,layers=len(numfilt),numfilt=numfilt)\n",
    "\n",
    "\n",
    "#Prepare folder to save network\n",
    "if not os.path.isdir(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not do_train and not os.path.isdir(model_path+'results'):\n",
    "    os.makedirs(model_path+'results')\n",
    "elif os.path.isdir(model_path+'results/polygons.csv'):\n",
    "    os.remove(model_path+'results/polygons.csv')\n",
    "\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#Initialize CNN\n",
    "optimizer = tf.train.AdamOptimizer(1e-4, epsilon=1e-6)\n",
    "apply_gradients = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    tf_u, tf_v, tf_du, tf_dv, tf_Du, tf_Dv, tf_u0, tf_v0, tf_du0, tf_dv0, \\\n",
    "    tf_alpha, tf_beta, tf_kappa = snake_graph(out_size, L)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(n,i,mode):\n",
    "    # mode (str): train or test\n",
    "    batch_ind = np.arange(i,i+batch_size)\n",
    "    batch = np.copy(images[:, :, :, batch_ind])\n",
    "    batch_mask = np.copy(masks[:, :, :, batch_ind])\n",
    "    thisGT = np.copy(GT[:, :, batch_ind[0]])\n",
    "    if mode is 'train':\n",
    "        ang = np.random.rand() * 360\n",
    "        for j in range(len(batch_ind)):\n",
    "            for b in range(batch.shape[2]):\n",
    "                batch[:, :, b, j] = imrotate(batch[:, :, b, j], ang)\n",
    "            batch_mask[:, :, 0, j] = imrotate(batch_mask[:, :, 0, j], ang, resample='nearest')\n",
    "        R = [[np.cos(ang * np.pi / 180), np.sin(ang * np.pi / 180)],\n",
    "             [-np.sin(ang * np.pi / 180), np.cos(ang * np.pi / 180)]]\n",
    "        thisGT -= out_size / 2\n",
    "        thisGT = np.matmul(thisGT, R)\n",
    "        thisGT += out_size / 2\n",
    "    # prediction_np = sess.run(prediction,feed_dict={x:batch})\n",
    "    tic = time.time()\n",
    "    [mapE, mapA, mapB, mapK, l2] = sess.run([predE, predA, predB, predK, l2loss], feed_dict={x: batch})\n",
    "    mapA = np.maximum(mapA, 0)\n",
    "    mapB = np.maximum(mapB,0)\n",
    "    mapK = np.maximum(mapK, 0)\n",
    "    #print('%.2f' % (time.time() - tic) + ' s tf inference')\n",
    "    if mode is 'train':\n",
    "        for j in range(mapK.shape[3]):\n",
    "            mapK[:, :, 0, j] -= batch_mask[:, :, 0, j] * 0.5 - 0.5 / 2\n",
    "        # mapE_aug[:,:,0,j] = mapE[:,:,0,j]+np.maximum(0,20-batch_dists[:,:,0,j])*max_val/50\n",
    "    # Do snake inference\n",
    "    s = np.linspace(0, 2 * np.pi, L)\n",
    "    init_u = out_size / 2 + 20 * np.cos(s)\n",
    "    init_v = out_size / 2 + 20 * np.sin(s)\n",
    "    init_u = init_u.reshape([L, 1])\n",
    "    init_v = init_v.reshape([L, 1])\n",
    "    init_snake = np.array([init_u[:, 0], init_v[:, 0]]).T\n",
    "    for j in range(batch_size):\n",
    "        snake, snake_hist = snake_process(mapE, mapA, mapB, mapK, init_snake)\n",
    "        # Get last layer gradients\n",
    "        M = mapE.shape[0]\n",
    "        N = mapE.shape[1]\n",
    "        der1, der2 = derivatives_poly(snake)\n",
    "\n",
    "\n",
    "        der1_GT, der2_GT = derivatives_poly(thisGT)\n",
    "\n",
    "        grads_arrayE = mapE * 0.01\n",
    "        grads_arrayA = mapA * 0.01\n",
    "        grads_arrayB = mapB * 0.01\n",
    "        grads_arrayK = mapK * 0.01\n",
    "        grads_arrayE[:, :, 0, 0] -= draw_poly(snake, 1, [M, N],12) - draw_poly(thisGT, 1, [M, N],12)\n",
    "        grads_arrayA[:, :, 0, 0] -= (np.mean(der1) - np.mean(der1_GT))\n",
    "        grads_arrayB[:, :, 0, 0] -= (draw_poly(snake, der2, [M, N],12) - draw_poly(thisGT, der2_GT, [M, N],12))\n",
    "        mask_gt = draw_poly_fill(thisGT, [M, N])\n",
    "        mask_snake = draw_poly_fill(snake, [M, N])\n",
    "        grads_arrayK[:, :, 0, 0] -= mask_gt - mask_snake\n",
    "\n",
    "        intersection = (mask_gt+mask_snake) == 2\n",
    "        union = (mask_gt + mask_snake) >= 1\n",
    "        iou = np.sum(intersection) / np.sum(union)\n",
    "    if mode is 'train':\n",
    "        tic = time.time()\n",
    "        apply_gradients.run(\n",
    "            feed_dict={x: batch, grad_predE: grads_arrayE, grad_predA: grads_arrayA, grad_predB: grads_arrayB,\n",
    "                       grad_predK: grads_arrayK, grad_l2loss: 1})\n",
    "        #print('%.2f' % (time.time() - tic) + ' s apply gradients')\n",
    "        #print('IoU = %.2f' % (iou))\n",
    "    #if mode is 'test':\n",
    "        #print('IoU = %.2f' % (iou))\n",
    "    if do_plot and n>=99 : # end_epoch=100:\n",
    "        plot_snakes(snake, snake_hist, thisGT, mapE, mapA, mapB, mapK, \\\n",
    "                grads_arrayE, grads_arrayA, grads_arrayB, grads_arrayK, batch, batch_mask)\n",
    "        #plt.show()\n",
    "    return iou,snake\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jovyan/work/DSAC/notebooks/../models/vaihingen/model-99\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key Variable/Adam not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-10-d0072d437149>:56) ]]\n\t [[save_1/RestoreV2/_95]]\n  (1) Not found: Key Variable/Adam not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-10-d0072d437149>:56) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_1/RestoreV2':\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-d0072d437149>\", line 56, in <module>\n    saver = tf.train.Saver()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key Variable/Adam not found in checkpoint\n\t [[{{node save_1/RestoreV2}}]]\n\t [[save_1/RestoreV2/_95]]\n  (1) Not found: Key Variable/Adam not found in checkpoint\n\t [[{{node save_1/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1286\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key Variable/Adam not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-10-d0072d437149>:56) ]]\n\t [[save_1/RestoreV2/_95]]\n  (1) Not found: Key Variable/Adam not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-10-d0072d437149>:56) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_1/RestoreV2':\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-d0072d437149>\", line 56, in <module>\n    saver = tf.train.Saver()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f6f49b92a60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1302\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key Variable/Adam not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-10-d0072d437149>:56) ]]\n\t [[save_1/RestoreV2/_95]]\n  (1) Not found: Key Variable/Adam not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-10-d0072d437149>:56) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_1/RestoreV2':\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-d0072d437149>\", line 56, in <module>\n    saver = tf.train.Saver()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/opt/conda/envs/tf_1_14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as sess:\n",
    "    sess2 = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True))\n",
    "    save_path = tf.train.latest_checkpoint(model_path)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    start_epoch = 0\n",
    "    if save_path is not None:\n",
    "        saver.restore(sess,save_path)\n",
    "        start_epoch = int(save_path.split('-')[-1].split('.')[0])+1\n",
    "\n",
    "    if do_train:\n",
    "        end_epoch = 100\n",
    "    else:\n",
    "        end_epoch = start_epoch + 1\n",
    "        polygons_csvfile = open(model_path + 'results/' 'polygons.csv', 'a', newline='')\n",
    "        polygons_writer = csv.writer(polygons_csvfile)\n",
    "\n",
    "    for n in range(start_epoch,end_epoch):\n",
    "        iou_test = 0\n",
    "        iou_train = 0\n",
    "        iter_count = 0\n",
    "        if do_train:\n",
    "            for i in range(0,100,batch_size):\n",
    "                #print(i)\n",
    "                #Do CNN inference\n",
    "                new_iou_train,snake = epoch(n,i,'train')\n",
    "                iou_train += new_iou_train\n",
    "                iter_count += 1\n",
    "                if iter_count == 1:\n",
    "                    print('Train. Epoch ' + str(n) + '. Iter ' + str(iter_count) + '/' + str(100) + ', IoU = %.2f' % (\n",
    "                        iou_train / iter_count))\n",
    "            iou_train /= 100\n",
    "\n",
    "            saver.save(sess,model_path+'model', global_step=n)\n",
    "        iter_count = 0\n",
    "        for i in range(start_test,168):\n",
    "            new_iou_test, snake = epoch(n, i, 'test')\n",
    "            if not do_train:\n",
    "                list_to_write = [len(snake)]\n",
    "                snake = np.reshape(snake,2*len(snake)).tolist()\n",
    "                for el in snake:\n",
    "                    list_to_write.append(el)\n",
    "                polygons_writer.writerow(list_to_write)\n",
    "            iou_test += new_iou_test\n",
    "            iter_count += 1\n",
    "            if iter_count == 1:\n",
    "                print('Test. Epoch ' + str(n) + '. Iter ' + str(iter_count) + '/' + str(68) + ', IoU = %.2f' % (\n",
    "                    iou_test / iter_count))\n",
    "                \n",
    "        iou_test /= iter_count\n",
    "        if not do_train:\n",
    "            iou_csvfile = open(model_path + 'iuo_train_test.csv', 'a', newline='')\n",
    "            iou_writer = csv.writer(iou_csvfile)\n",
    "            iou_writer.writerow([n,iou_train,iou_test])\n",
    "            iou_csvfile.close()\n",
    "            polygons_csvfile.close()\n",
    "\n",
    "\n",
    "#if os.path.isfile(model_path+'iuo_train_test.csv'):\n",
    "\n",
    "#else:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as sess:\n",
    "    sess2 = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True))\n",
    "    save_path = tf.train.latest_checkpoint(model_path)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    start_epoch = 0\n",
    "    if save_path is not None:\n",
    "        saver.restore(sess,save_path)\n",
    "        start_epoch = int(save_path.split('-')[-1].split('.')[0])+1\n",
    "\n",
    "    if do_train:\n",
    "        end_epoch = 100\n",
    "    else:\n",
    "        end_epoch = start_epoch + 1\n",
    "        polygons_csvfile = open(model_path + 'results/' 'polygons.csv', 'a', newline='')\n",
    "        polygons_writer = csv.writer(polygons_csvfile)\n",
    "\n",
    "    for n in range(start_epoch,end_epoch):\n",
    "        iou_test = 0\n",
    "        iou_train = 0\n",
    "        iter_count = 0\n",
    "        if do_train:\n",
    "            for i in range(0,100,batch_size):\n",
    "                #print(i)\n",
    "                #Do CNN inference\n",
    "                new_iou_train,snake = epoch(n,i,'train')\n",
    "                iou_train += new_iou_train\n",
    "                iter_count += 1\n",
    "                print('Train. Epoch ' + str(n) + '. Iter ' + str(iter_count) + '/' + str(100) + ', IoU = %.2f' % (\n",
    "                iou_train / iter_count))\n",
    "            iou_train /= 100\n",
    "\n",
    "            saver.save(sess,model_path+'model', global_step=n)\n",
    "        iter_count = 0\n",
    "        for i in range(start_test,168):\n",
    "            new_iou_test, snake = epoch(n, i, 'test')\n",
    "            if not do_train:\n",
    "                list_to_write = [len(snake)]\n",
    "                snake = np.reshape(snake,2*len(snake)).tolist()\n",
    "                for el in snake:\n",
    "                    list_to_write.append(el)\n",
    "                polygons_writer.writerow(list_to_write)\n",
    "            iou_test += new_iou_test\n",
    "            iter_count += 1\n",
    "            print('Test. Epoch ' + str(n) + '. Iter ' + str(iter_count) + '/' + str(68) + ', IoU = %.2f' % (\n",
    "            iou_test / iter_count))\n",
    "        iou_test /= iter_count\n",
    "        if not do_train:\n",
    "            iou_csvfile = open(model_path + 'iuo_train_test.csv', 'a', newline='')\n",
    "            iou_writer = csv.writer(iou_csvfile)\n",
    "            iou_writer.writerow([n,iou_train,iou_test])\n",
    "            iou_csvfile.close()\n",
    "            polygons_csvfile.close()\n",
    "\n",
    "\n",
    "#if os.path.isfile(model_path+'iuo_train_test.csv'):\n",
    "\n",
    "#else:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/vaihingen/model-2',\n",
       " 'models/vaihingen/model-3',\n",
       " 'models/vaihingen/model-4',\n",
       " 'models/vaihingen/model-5',\n",
       " 'models/vaihingen/model-6']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.last_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable\n\t [[Node: _retval_Variable_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/tf_gpu_1_4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_gpu_1_4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_gpu_1_4/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[Node: _retval_Variable_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-294097fee224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_gpu_1_4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_gpu_1_4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_gpu_1_4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf_gpu_1_4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[Node: _retval_Variable_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]"
     ]
    }
   ],
   "source": [
    "with h5py.File('./models/vaihingen/model.hdf5', 'w') as f:\n",
    "    for var in tf.trainable_variables():\n",
    "        key = var.name.replace('/', ' ')\n",
    "        value = sess2.run(var)\n",
    "        f.create_dataset(key, data=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(7, 7, 3, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_8:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_12:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_13:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_14:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_15:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_16:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_17:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_18:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_19:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_20:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_21:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_22:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_23:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_24:0' shape=(1, 1, 768, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_25:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_26:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_27:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_28:0' shape=(1, 1, 256, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_29:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_30:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_31:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_32:0' shape=(1, 1, 64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_33:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_34:0' shape=(1, 1, 64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_35:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_36:0' shape=(1, 1, 64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_37:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_38:0' shape=(1, 1, 64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_39:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU 1.14",
   "language": "python",
   "name": "tf_1_14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
